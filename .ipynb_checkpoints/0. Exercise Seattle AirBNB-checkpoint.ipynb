{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle AirBNB-Data prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is intended to carry out an analysis of the Seattle AirBNB Data and explore opportunities for those hosts that look to improve their performance without spending money.\n",
    "\n",
    "The questions we are looking to explore are the following:\n",
    "\n",
    "1. What are the top 5 features which have more impact in the price? i.e. zipcode? square_feet?\n",
    "2. What impact have the ratings over the price? \n",
    "3. What are the top 5 features which customers value when rating their stay that depend only on the host? i.e. experiences_offered? cleanliness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUICK - DATA EXPLORATION - General Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = pd.read_csv('csv/reviews.csv')\n",
    "df_r.iloc[100:125,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Shape Tuple: ',df_r.shape,'\\n',\n",
    "      'No. Rows: ',df_r.shape[0],'\\n',\n",
    "      'No. Cols: ',df_r.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # value counts the list of cols types\n",
    "df_r.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of different [id]´s:',df_r['id'].value_counts().count())\n",
    "\n",
    "print('No. of different [listing_id]´s:',df_r['listing_id'].value_counts().count())\n",
    "\n",
    "print('No. of different [reviewer_id]´s:',df_r['reviewer_id'].value_counts().count())\n",
    "print('No. of [reviewer_name]´s:',df_r['reviewer_name'].value_counts().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the reviwerer_id with most reviews\n",
    "User_id_max = df_r['reviewer_id'].value_counts().index[0]\n",
    "User_id_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides the reviewer_name of the User_id_max\n",
    "User_name_max = df_r[df_r['reviewer_id'] == User_id_max]['reviewer_name'].values[0]\n",
    "User_name_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the max number of reviews of people with the same name as User_name_max, and compares with User_id_max\n",
    "print('Total number of reviweres called',User_name_max,':',df_r[df_r['reviewer_name'] == 'Amanda']['reviewer_id'].count())\n",
    "\n",
    "print('Total reviwes done by reviewer_id:',User_id_max,' whos name is also ',User_name_max,':',df_r[df_r['reviewer_id'] == User_id_max]['reviewer_name'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclussions\n",
    "\n",
    "* No. of different [id]´s: 84849\n",
    "* No. of different [listing_id]´s: 3191\n",
    "* No. of different [reviewer_id]´s: 75730\n",
    "* No. of [reviewer_name]´s: 14380\n",
    "\n",
    "\n",
    "1. The [id] is the review Id and it seems to be UNIQUE.\n",
    "2. The [listing_id] must be owner´s airbnb id, which can have more than 1 review.\n",
    "3. The [reviewer_id] must be the person that utilises the home, which can leave more than 1 review.\n",
    "4. The [reviewer_name] equates to the reviewer id, but the names however are not unique as the [reviewer_id], as confirmed with the code above with Amanda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### listings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l = pd.read_csv('csv/listings.csv')\n",
    "df_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Shape Tuple: ',df_l.shape,'\\n',\n",
    "      'No. Rows: ',df_l.shape[0],'\\n',\n",
    "      'No. Cols: ',df_l.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # value counts the list of cols types\n",
    "df_l.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of different [id]´s:',df_l['id'].value_counts().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclussions\n",
    "\n",
    "* No. of different [id]´s: 3818\n",
    "\n",
    "1. The [id] is the listing Id and it is UNIQUE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calendar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_csv('csv/calendar.csv')\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' Shape Tuple: ',df_c.shape,'\\n',\n",
    "      'No. Rows: ',df_c.shape[0],'\\n',\n",
    "      'No. Cols: ',df_c.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of different [listing_id]´s:',df_c['listing_id'].value_counts().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['date'].value_counts().count() * df_c['listing_id'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['date'] = pd.to_datetime(df_c['date'],format=\"%Y/%m/%d\")\n",
    "print('Initial Date:',df_c['date'].min())\n",
    "print('Last Date:',df_c['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclussions\n",
    "\n",
    "* No. of different [listing_id]´s: 3818\n",
    "\n",
    "* Initial Date: 2016-01-04 00:00:00\n",
    "* Last Date: 2017-01-02 00:00:00\n",
    "\n",
    "Holds a list with the availability of all [listing_id]´s throught out the period the year 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclussion QUICK - DATA EXPLORATION of all x3 spread sheets\n",
    "\n",
    "1. review.csv: The [id] is the review Id and it seems to be UNIQUE for this list (84849, 6). Cols:\n",
    "\n",
    "\n",
    "    listing_id        3191\n",
    "    id               84849\n",
    "    date              1930\n",
    "    reviewer_id      75730\n",
    "    reviewer_name    14380\n",
    "    comments         84136\n",
    "\n",
    "\n",
    "2.  listings.csv: The [id] is the listing Id and it seems to be UNIQUE for this list (3818, 92). Cols:\n",
    "\n",
    "\n",
    "    Id                                  3818\n",
    "    listing_url                         3818\n",
    "    scrape_id                              1\n",
    "    last_scraped                           1\n",
    "    name                                3792\n",
    "                                        ... \n",
    "    cancellation_policy                    3\n",
    "    require_guest_profile_picture          2\n",
    "    require_guest_phone_verification       2\n",
    "    calculated_host_listings_count        18\n",
    "    reviews_per_month                    654\n",
    "\n",
    "\n",
    "3. calendar.csv: The [date] x [listing_id] (1393570, 4) seems to be UNIQUE for this list (1393570, 4). Cols:\n",
    "\n",
    "\n",
    "    listing_id    3818\n",
    "    date           365\n",
    "    available        2\n",
    "    price          669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_l.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Merge relevant dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate review.csv with listings.csv\n",
    "\n",
    "df_l.rename(columns={'id':'listing_id'},inplace=True)\n",
    "\n",
    "df = pd.merge(df_r, df_l, on = \"listing_id\", how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "(df.isnull().sum() * 100 / len(df)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Numerical and Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a columns with the quantitative Data\n",
    "num_vbles = df.select_dtypes(exclude = ['object']).columns\n",
    "\n",
    "# Creates a columns with the categorical Data\n",
    "cat_vbles = df.select_dtypes(include = ['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[num_vbles].isnull().sum() * 100 / len(df)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[cat_vbles].isnull().sum() * 100 / len(df)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 25% missing values to avoid overfitting\n",
    "df.drop(df.columns[df.isnull().mean() > 0.25],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a number of categorical columns that actually should be numerical data: monthly_price, security_deposit, \n",
    "# weekly_price, cleaning_fee & price\n",
    "\n",
    "# Function that converts from cat data to numerical data:\n",
    "\n",
    "conv_list = ['price','extra_people']\n",
    "\n",
    "def conv_float(df,col_list):\n",
    "    for col in col_list:\n",
    "        df[col] = df[col].map(lambda x: x.replace(',',''))\n",
    "        df[col] = df[col].map(lambda x: x.replace('$',''))\n",
    "        df[col] = df[col].astype('float')\n",
    "\n",
    "conv_float(df,conv_list)\n",
    "\n",
    "# Creates a columns with the quantitative Data\n",
    "num_vbles = df.select_dtypes(exclude = ['object']).columns\n",
    "\n",
    "# Creates a columns with the categorical Data\n",
    "cat_vbles = df.select_dtypes(include = ['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object % - to float (for the numerical category)\n",
    "\n",
    "df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype('float') / 100.0\n",
    "df['host_response_rate'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object % - to float (for the numerical category)\n",
    "\n",
    "df['host_acceptance_rate'] = df['host_acceptance_rate'].str.rstrip('%').astype('float') / 100.0\n",
    "df['host_acceptance_rate'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm price is in the num_vbles list:\n",
    "(df[num_vbles].isnull().sum() * 100 / len(df)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Cols with only one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that only have 1 unique value. These columns will not add any information:\n",
    "l = []\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() == 1:\n",
    "        l.append(col)\n",
    "df.drop(l,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing values in Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode for the # bathrooms & bedroooms:\n",
    "fill_mode = lambda col: col.fillna(col.mode()[0])\n",
    "\n",
    "df[['bathrooms','bedrooms']] = df[['bathrooms','bedrooms']].apply(fill_mode)\n",
    "\n",
    "# Creates a columns with the quantitative Data\n",
    "num_vbles = df.select_dtypes(exclude = ['object']).columns\n",
    "\n",
    "# Creates a columns with the categorical Data\n",
    "cat_vbles = df.select_dtypes(include = ['object']).columns\n",
    "\n",
    "# Confirm the mode of ['bathrooms','bedrooms'] has been calculated:\n",
    "(df[num_vbles].isnull().sum() * 100 / len(df)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any other missing values\n",
    "df.dropna(subset = num_vbles, axis=0, inplace = True)\n",
    "\n",
    "# Confirm the numerical data has no longer any missing values:\n",
    "(df[num_vbles].isnull().sum() * 100 / len(df)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing values in Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[cat_vbles].isnull().sum() * 100 / len(df)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_vbles].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[df.isnull().mean() > 0.25],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any column which holds > 50 unique variables\n",
    "df[cat_vbles].nunique() > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[cat_vbles].columns[df[cat_vbles].nunique() > 50],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a columns with the categorical Data\n",
    "cat_vbles = df.select_dtypes(include = ['object']).columns\n",
    "df[cat_vbles].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any other missing values\n",
    "df.dropna(subset = cat_vbles, axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we still have sufficient amount of information\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns that create problems on the model\n",
    "df.drop(['listing_id','id','host_id','reviewer_id','latitude','longitude','city','smart_location','host_listings_count','host_total_listings_count','calendar_updated'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy on the Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_vbles:\n",
    "    try:\n",
    "        df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=False)], axis=1)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Linear Regression on Price (Q1 & Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into explanatory and response variables\n",
    "X = df.drop(['price'], axis=1)\n",
    "y = df['price']\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate & Fit\n",
    "lm_model = LinearRegression(normalize=True)\n",
    "lm_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict using your model\n",
    "y_test_preds = lm_model.predict(X_test)\n",
    "y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "#Score using your model\n",
    "test_score = r2_score(y_test, y_test_preds)\n",
    "train_score = r2_score(y_train, y_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print training and testing score\n",
    "print(\"The rsquared on the training data was {}.  The rsquared on the test data was {}.\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_lm_mod(X, y, cutoffs, test_size = .30, random_state=42, plot=True):\n",
    "    '''\n",
    "    INPUT\n",
    "    X - pandas dataframe, X matrix\n",
    "    y - pandas dataframe, response variable\n",
    "    cutoffs - list of ints, cutoff for number of non-zero values in dummy categorical vars\n",
    "    test_size - float between 0 and 1, default 0.3, determines the proportion of data as test data\n",
    "    random_state - int, default 42, controls random state for train_test_split\n",
    "    plot - boolean, default 0.3, True to plot result\n",
    "\n",
    "    OUTPUT\n",
    "    r2_scores_test - list of floats of r2 scores on the test data\n",
    "    r2_scores_train - list of floats of r2 scores on the train data\n",
    "    lm_model - model object from sklearn\n",
    "    X_train, X_test, y_train, y_test - output from sklearn train test split used for optimal model\n",
    "    '''\n",
    "    # Define x3 empty lists & x1 empty dict\n",
    "    r2_scores_test, r2_scores_train, num_feats, results = [], [], [], dict()\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "\n",
    "        #reduce X matrix\n",
    "        reduce_X = X.iloc[:, np.where((X.sum() > cutoff) == True)[0]]\n",
    "        num_feats.append(reduce_X.shape[1])\n",
    "        # Explanation\n",
    "        # 1. X.sum() provides a Series (2 cols) with the cols names and the sum of the values for all the index\n",
    "        # 2. np.where((X.sum() > cutoff) == True)[0] provides a list of integers where its true for these columns\n",
    "        # 3. df.iloc[:,[...]]: reduces X down to the columns selected above in the list\n",
    "        # 4. num_feats records the number of columns/features for each cutoff value in a list\n",
    "        \n",
    "        #split the data into train and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "        #fit the model and obtain pred response\n",
    "        lm_model = LinearRegression(normalize=True)\n",
    "        lm_model.fit(X_train, y_train)\n",
    "        y_test_preds = lm_model.predict(X_test)\n",
    "        y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "        #append the r2 value from the test set\n",
    "        r2_scores_test.append(r2_score(y_test, y_test_preds))\n",
    "        r2_scores_train.append(r2_score(y_train, y_train_preds))\n",
    "        results[str(cutoff)] = r2_score(y_test, y_test_preds)\n",
    "        # Explanation\n",
    "        # 1. r2_scores_test & r2_scores_train are lists recording the results for each cutoff value\n",
    "        # 2. results is a dictionary recording ...\n",
    "             \n",
    "    if plot == True:\n",
    "        plt.plot(num_feats, r2_scores_test, label=\"Test\", alpha=.5)\n",
    "        plt.plot(num_feats, r2_scores_train, label=\"Train\", alpha=.5)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('Rsquared')\n",
    "        plt.title('Rsquared by Number of Features')\n",
    "        plt.legend(loc=1)\n",
    "        plt.show()\n",
    "\n",
    "    best_cutoff = max(results, key=results.get)\n",
    "\n",
    "    #reduce X matrix\n",
    "    reduce_X = X.iloc[:, np.where((X.sum() > int(best_cutoff)) == True)[0]]\n",
    "    num_feats.append(reduce_X.shape[1])\n",
    "\n",
    "    #split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reduce_X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "    #fit the model\n",
    "    lm_model = LinearRegression(normalize=True)\n",
    "    lm_model.fit(X_train, y_train)\n",
    "\n",
    "    return r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffs here pertains to the number of missing values allowed in the used columns.\n",
    "#Therefore, lower values for the cutoff provides more predictors in the model.\n",
    "cutoffs = [40000, 20000, 10000, 5000, 2500, 1000, 500, 250, 100, 50, 20, 10, 5, 2]\n",
    "\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = find_optimal_lm_mod(X, y, cutoffs, test_size = 0.30, random_state=42, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "#A quick look at the top results\n",
    "coef_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclussions Q1 & Q2\n",
    "\n",
    "Q1 - What are the top 5 features which have more impact in the price? The top 5 features that have an impact is related to:\n",
    "\n",
    "* Property_type\n",
    "* host_has_profile_pic (very interesting)\n",
    "* neighbourhood_group_cleansed\n",
    "* zipcode\n",
    "* room_type\n",
    "\n",
    "Q3 - What impact have the ratings over the price? \n",
    "\n",
    "* It has an impact of 2.415173 dollars per point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Linear Regression on Review (Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into explanatory and response variables\n",
    "X = df.drop(['review_scores_rating'], axis=1)\n",
    "y = df['review_scores_rating']\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate & Fit\n",
    "lm_model = LinearRegression(normalize=True)\n",
    "lm_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict using your model\n",
    "y_test_preds = lm_model.predict(X_test)\n",
    "y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "#Score using your model\n",
    "test_score = r2_score(y_test, y_test_preds)\n",
    "train_score = r2_score(y_train, y_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print training and testing score\n",
    "print(\"The rsquared on the training data was {}.  The rsquared on the test data was {}.\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffs here pertains to the number of missing values allowed in the used columns.\n",
    "#Therefore, lower values for the cutoff provides more predictors in the model.\n",
    "cutoffs = [40000, 20000, 10000, 5000, 2500, 1000, 500, 250, 100, 50, 20, 10, 5, 2]\n",
    "\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = find_optimal_lm_mod(X, y, cutoffs, test_size = 0.30, random_state=42, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "#A quick look at the top results\n",
    "coef_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclussions Q3\n",
    "\n",
    "Q3 - What are the top 5 features which customers value when rating their stay that depend only on the host? \n",
    "\n",
    "Top 5 features:\n",
    "\n",
    "* host_acceptance_rate - negatively. \n",
    "* review_scores_cleanliness - positively\n",
    "* review_scores_communication - positevely\n",
    "* review_scores_checkin - positevely\n",
    "* host_is_superhost_t - positevely\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
